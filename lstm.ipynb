{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import vocab\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(s):\n",
    "    return [w.text.lower() for w in nlp(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rew_field = data.Field(sequential=True, \n",
    "                       tokenize=tokenizer, \n",
    "                       include_lengths=True, \n",
    "                       use_vocab=True,\n",
    "                       fix_length=512)\n",
    "\n",
    "label_field = data.Field(sequential=False, \n",
    "                         use_vocab=False, \n",
    "                         pad_token=None, \n",
    "                         unk_token=None)\n",
    "\n",
    "train_val_fields = [\n",
    "    ('Review', rew_field), \n",
    "    ('Label', label_field)\n",
    "]\n",
    "\n",
    "dtrain, dval, dtest = data.TabularDataset.splits(path='/kaggle/input/sentimentanalysis/', \n",
    "                                            format='csv', \n",
    "                                            train='train_df.csv', \n",
    "                                            validation='valid_df.csv',\n",
    "                                            test='test_df.csv',\n",
    "                                            fields=train_val_fields, \n",
    "                                            skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.44 s, sys: 274 ms, total: 2.72 s\n",
      "Wall time: 2.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vec = vocab.Vectors(\"../input/sentimentanalysis/glove.6B.200d.txt\")\n",
    "rew_field.build_vocab(dtrain, dval, dtest, max_size=100000, vectors=vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 641638),\n",
       " ('the', 336713),\n",
       " ('.', 327192),\n",
       " ('and', 164107),\n",
       " ('a', 163009),\n",
       " ('of', 145864),\n",
       " ('to', 135720),\n",
       " ('is', 107351),\n",
       " ('br', 101872),\n",
       " ('it', 96357),\n",
       " ('in', 93968),\n",
       " ('  ', 91970),\n",
       " ('i', 87832),\n",
       " ('this', 76000),\n",
       " ('that', 73623),\n",
       " ('s', 65969),\n",
       " ('   ', 63412),\n",
       " ('was', 48233),\n",
       " ('as', 46933),\n",
       " ('for', 44343)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rew_field.vocab.freqs.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "bs = 100\n",
    "trainl, validl, testl = data.BucketIterator.splits(datasets=(dtrain, dval, dtest),\n",
    "                                                   batch_sizes=(bs, bs, bs),\n",
    "                                                   sort_key=lambda x: len(x.Review),\n",
    "                                                   device=device, \n",
    "                                                   sort_within_batch=True)\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': <torchtext.data.field.Field at 0x7f7e1f5d4a10>,\n",
       " 'Label': <torchtext.data.field.Field at 0x7f7e1f5d4a50>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(trainl))\n",
    "print(len(batch))\n",
    "batch.dataset.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    \n",
    "    def __init__(self, batch_obj, data_field, label_field):\n",
    "        self.batch_obj = batch_obj\n",
    "        self.data_field = data_field\n",
    "        self.label_field = label_field\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.batch_obj)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.batch_obj:\n",
    "            data = getattr(batch, self.data_field)\n",
    "            label = getattr(batch, self.label_field)\n",
    "            yield data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = BatchGenerator(trainl, 'Review', 'Label')\n",
    "batch = next(iter(train_batch))\n",
    "ba, l = batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The LSTM model for sentiment analysis\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, pretrained_emb, drop_prob=0.5, bidirectional=False):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim).from_pretrained(pretrained_emb)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True, bidirectional=self.bidirectional)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            self.fc1 = nn.Linear(2*self.hidden_dim, self.hidden_dim)\n",
    "            self.fc2 = nn.Linear(self.hidden_dim, self.output_size)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(self.hidden_dim, 100)\n",
    "            self.fc2 = nn.Linear(100, self.output_size)\n",
    "            \n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, lengths, hidden=None):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state\n",
    "        \"\"\"\n",
    "        batch_size = x.size(1)\n",
    "        x = x.transpose(0, 1)\n",
    "        \n",
    "        if not hidden:\n",
    "            hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        x = x.long()\n",
    "        \n",
    "        embeds = self.embedding(x)\n",
    "      \n",
    "        pack_embeds = pack_padded_sequence(embeds, lengths, batch_first=True)\n",
    "        lstm_out, hidden = self.lstm(pack_embeds, hidden)\n",
    "        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=True)\n",
    "\n",
    "        out = F.adaptive_avg_pool1d(lstm_out.permute(0, 2, 1), 1).squeeze(2)\n",
    "            \n",
    "        out = self.dropout(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.dropout(self.lrelu(out))\n",
    "        out = self.fc2(out)\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        Initializes hidden state\n",
    "        \"\"\"\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "            hidden = (weight.new(self.n_layers*(1 + self.bidirectional), batch_size, \n",
    "                                 self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers*(1 + self.bidirectional), batch_size, \n",
    "                                 self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers*(1 + self.bidirectional), batch_size, \n",
    "                                 self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers*(1 + self.bidirectional), batch_size, \n",
    "                                 self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(74067, 200)\n",
      "  (lstm): LSTM(200, 256, num_layers=3, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (lrelu): LeakyReLU(negative_slope=0.01)\n",
      "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_loader = BatchGenerator(trainl, 'Review', 'Label') \n",
    "valid_loader = BatchGenerator(validl, 'Review', 'Label') \n",
    "test_loader = BatchGenerator(testl, 'Review', 'Label') \n",
    "\n",
    "output_size = 1\n",
    "embedding_dim = rew_field.vocab.vectors.shape[1]\n",
    "hidden_dim = 256\n",
    "n_layers = 3\n",
    "epochs = 20\n",
    "\n",
    "vocab_size = len(rew_field.vocab.stoi)\n",
    "pretrained_emb = rew_field.vocab.vectors \n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, \n",
    "                   pretrained_emb, bidirectional=True)\n",
    "\n",
    "net.to(device)\n",
    "print(net)\n",
    "\n",
    "lr=0.001\n",
    "wd = 0.0001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr) \n",
    "\n",
    "total_steps = len(train_loader)*epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5... Step: 200... Loss: 0.342713... Val Loss: 0.360510\n",
      "Epoch: 2/5... Step: 400... Loss: 0.419579... Val Loss: 0.314463\n",
      "Epoch: 3/5... Step: 600... Loss: 0.459653... Val Loss: 0.282613\n",
      "Epoch: 4/5... Step: 800... Loss: 0.347845... Val Loss: 0.284480\n",
      "Epoch: 5/5... Step: 1000... Loss: 0.265060... Val Loss: 0.267617\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "train_len = len(train_loader)\n",
    "val_len = len(valid_loader)\n",
    "\n",
    "\n",
    "\n",
    "epochs = 5 # 4-5 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 200\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    h = net.init_hidden(bs)\n",
    "\n",
    "    tl = 0\n",
    "    for (inputs, lengths), labels in train_loader:\n",
    "        net.train()\n",
    "        counter += 1\n",
    "\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        output, h = net(inputs, lengths, h)\n",
    "\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if counter % print_every == 0:\n",
    "            vl = 0\n",
    "            train_loss.append(loss)\n",
    "\n",
    "            net.eval()\n",
    "            for (inputs, lengths), labels in valid_loader:\n",
    "                output, val_h = net(inputs, lengths)\n",
    "                vloss = criterion(output.squeeze(), labels.float())\n",
    "                vl += vloss.item()\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            val_loss.append(vl/val_len)\n",
    "\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.6f}...\".format(loss),\n",
    "                      \"Val Loss: {:.6f}\".format(vl/val_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(loader=test_loader):\n",
    "    test_losses = [] \n",
    "    num_correct = 0\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    for (inputs, lengths), labels in test_loader:\n",
    "\n",
    "        output, h = net(inputs, lengths)\n",
    "\n",
    "        test_loss = criterion(output.squeeze(), labels.float())\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "        pred = torch.round(output.squeeze())  \n",
    "\n",
    "        correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not device.type == 'cuda' else np.squeeze(correct_tensor.cpu().numpy())\n",
    "        num_correct += np.sum(correct)\n",
    "\n",
    "    \n",
    "    test_len = 2500\n",
    "    test_acc = num_correct/test_len\n",
    "    print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.889\n"
     ]
    }
   ],
   "source": [
    "get_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, review):\n",
    "    model.eval()\n",
    "    tokenized = tokenizer(review)\n",
    "    indexed = [rew_field.vocab.stoi[word] for word in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device).unsqueeze(1)\n",
    "    prediction = net(tensor, torch.LongTensor([tensor.size(0)]).to(device))\n",
    "    return prediction[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0035714663099497557"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_rew = \"This film is great\"\n",
    "predict_sentiment(net, pos_rew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7507160044469856e-08"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_rew = \"This film is terrible\"\n",
    "predict_sentiment(net, neg_rew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
